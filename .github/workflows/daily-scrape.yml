name: Daily Video Scrape
on:
  schedule:
    - cron: '5 * * * *' # 7:00 AM VN time
  workflow_dispatch:
jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repo
      uses: actions/checkout@v4
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4
    - name: Download credentials
      env:
        GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }}
      run: |
        echo "$GOOGLE_CREDENTIALS" > credentials.json
    - name: Run script
      run: python scrape_videos.py
    - name: Commit and push data.txt
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add data.txt
        git commit -m "Daily update: data.txt $(date +%Y-%m-%d)" || echo "No changes"
        git push
    - name: Upload artifacts
      uses: actions/upload-artifact@v4
      with:
        name: scrape-results
        path: |
          scrape_videos.log
          response_page_*.html
          data.txt
          temp_videos.csv
